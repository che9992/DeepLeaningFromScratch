{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft_max_function <hr/>\n",
    "Neural networks are available for both regression and classifications\n",
    "\n",
    "In general, using identity function for Regression and soft max function for classification\n",
    "\n",
    "identity function outputs the input as it is. \n",
    "\n",
    "The expression for soft max function is: \n",
    "\n",
    "# \\\\( y_k = \\frac{exp(a_k)}{\\sum_{i=1}^{K}exp(a_i)}\\\\)\n",
    " \n",
    "exp means exponential function\n",
    "\n",
    "### OK, Let's implement a soft max function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a) \n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pretty easy isn't it?, Let's recreate it as a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    return exp_a / sum_exp_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's perfect showing soft max function expression \n",
    "\n",
    "but there is one problem, overflow !\n",
    "\n",
    "As you can see, softmax uses exponential functions, but exponential functions outputs very large numbers.\n",
    "\n",
    "so, we need recreate it \n",
    "\n",
    "# \\\\( y_k = \\frac{exp(a_k)}{\\sum_{i=1}^{K}exp(a_i)} = \\frac{Cexp(a_k)}{C\\sum_{i=1}^{K}exp(a_i)} = \\frac{exp(a_k + logC)}{\\sum_{i=1}^{K}exp(a_i + logC)} = \\frac{exp(a_k + C')}{\\sum_{i=1}^{K}exp(a_i + C')}\\\\)\n",
    "\n",
    "i will show you one of example with the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\che99\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "C:\\Users\\che99\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1010., 1000., 990.])\n",
    "np.exp(a) / np.sum(np.exp(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you see? there is no number because overflow \n",
    "\n",
    "you wanna fix it ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1010., 1000., 990.])\n",
    "a = a - np.max(a)\n",
    "np.exp(a) / np.sum(np.exp(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's so easy , you just subtract the maximum number of inputs.\n",
    "\n",
    "Let's reimplement a soft max function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    a = a - np.max(a)\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    return exp_a / sum_exp_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1010,1000,990])\n",
    "softmax(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the characteristics of soft maxfunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after soft max : [0.01077126 0.00358544 0.04827345 0.87732862 0.00107991 0.05896132]\n",
      "sum of outputs :  1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([3.3, 2.2, 4.8, 7.7, 1,5])\n",
    "y = softmax(a)\n",
    "print('after soft max :', y)\n",
    "\n",
    "sum = 0\n",
    "for i in y:\n",
    "    sum += i\n",
    "print('sum of outputs : ', sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you realized? 'Soft maximum function' always outputs between 0 and 1\n",
    "\n",
    "and the sum of all the outputs is always 1\n",
    "\n",
    "we can think outpus are percentage because that characteristics \n",
    "\n",
    "you can interpret it as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 35.080 %\n",
      "1: 7.083 %\n",
      "2: 57.837 %\n"
     ]
    }
   ],
   "source": [
    "a = np.array([8.4, 6.8, 8.9])\n",
    "result = softmax(a)\n",
    "\n",
    "for i in range(3):\n",
    "    print('{}: {:.3f} %'.format(i, result[i]* 100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
